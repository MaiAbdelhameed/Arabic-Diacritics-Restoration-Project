{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing ideas: \n",
    "1) Removal of not arabic \n",
    "2) Removal and saving of diacritics \n",
    "3) Segementation\n",
    "4) Tokenization\n",
    "5) Lemmatization\n",
    "\n",
    "Feature Extraction ideas: \n",
    "1) POS\n",
    "2) Morphological quadruples\n",
    "3) Context\n",
    "4) Last character\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarabic in c:\\users\\mai\\anaconda3\\lib\\site-packages (0.6.15)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from pyarabic) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mai\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from Input_Utils import input_utils\n",
    "from Preprocessing import preprocessing_utils\n",
    "import pyarabic.araby as araby\n",
    "from pyarabic.araby import strip_tashkeel, is_arabicrange, strip_diacritics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics_and_save(text):\n",
    "    stripped = araby.strip_diacritics(text)\n",
    "    diacritics_dic = [{i: char} for i,char in enumerate(text) if char not in stripped]\n",
    "    return stripped, diacritics_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_arabic_char(text):\n",
    "    regex = re.compile('[^؀-ۿ ]')\n",
    "    result = regex.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = input_utils.read_input('Dataset/train.txt')\n",
    "text = train_dataset[0]\n",
    "result = remove_non_arabic_char(text)\n",
    "stripped, diacritics = remove_diacritics_and_save(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sentence is والله أسأل ، وبرسوله أتوسل ، أن ينفع به كما نفع بأصله ، وأن يغفر لمن نظر فيه بعين الإنصاف ، ودعا لمؤلفه بأن يدركه ربه جل وعلا بخفي الألطاف ، وبأن يمتعه بالنظر إلى وجهه ، ويمده بالإسعاف ، وحسبنا الله ونعم الوكيل ، ولا حول ولا قوة( 29 / 477 ). قوله : ( لاعن امرأته ) قال في الفتح : اللعان مأخوذ من اللعن ; لأن الملاعن يقول في الخامسة : لعنة الله عليه إن كان من الكاذبين , واختير لفظ اللعن دون الغضب في التسمية لأنه قول الرجل وهو الذي بدئ به في الآية , وهو أيضا يبدأ به . وقيل : سمي لعانا لأن اللعن : الطرد والإبعاد , وهو مشترك بينهما . وإنما خصت المرأة بلفظ الغضب لعظم الذنب بالنسبة إليها . ثم قال : وأجمعوا على أن اللعان مشروع , وعلى أنه لا يجوز مع عدم التحقق . واختلف في وجوبه على الزوج . وظاهر أحاديث الباب أن اللعان إنما يشرع بين الزوجين , وكذلك قوله تعالى : { والذين يرمون أزواجهم } الآية , فلو قال أجنبي لأجنبية : يا زانية وجب عليه حد القذف . قوله : ( ففرق رسول الله صلى الله عليه وسلم بينهما ) استدل به من قال إن الفرقة بين المتلاعنين لا تقع بنفس اللعان حتى يوقعها الحاكم وأجاب من قال : إن الفرقة تقع بنفس اللعان أن ذلك بيان حكم لا إيقاع فرقة . واحتجوا بما وقع منه صلى الله عليه وسلم في رواية بلفظ : { لا سبيل لك عليها } . وتعقب بأن الذي وقع جواب لسؤال الرجل عن ماله الذي أخذته منه . وأجيب بأن العبرة بعموم اللفظ , وهو نكرة في سياق النفي فيشمل المال والبدن ويقتضي نفي تسلطه عليها بوجه من الوجوه . ووقع في حديث لأبي داود عن ابن عباس { وقضى أن ليس عليه قوت ولا سكنى من أجل أنهما يفترقان بغير طلاق ولا متوفى عنها } , وهو ظاهر في أن الفرقة وقعت بينهما بنفس اللعان , وسيأتي تمام الكلام في الفرقة في الباب الذي بعد هذا : قوله : ( وألحق الولد بالمرأة ) قال الدارقطني : تفرد مالك بهذه الزيادة . وقال ابن عبد البر : ذكروا أن مالكا تفرد بهذه اللفظة , وقد جاءت من أوجه أخر , وقد جاءت في حديث سهل بن سعد عند أبي داود بلفظ : { فكان الولد ينسب إلى أمه } ومن رواية أخرى { وكان الولد يدعى إلى أمه } ومعنى قوله { ألحق الولد بأمه } : أي صيره لها وحدها ونفاه عن الزوج فلا توارث بينهما , وأما الأم فترث منه ما فرض الله لها وقد وقع في رواية من حديث سهل بن سعد بلفظ : { وكان ابنها يدعى لأمه } ثم جرت السنة في ميراثها أنها ترثه ويرث منها ما فرض الله لهما . وقيل : معنى إلحاقه بأمه أنه صيرها له أبا وأما , فترث جميع ماله إذا لم يكن له وارث آخر من ولد ونحوه , وهو قول ابن مسعود وواثلة وطائفة ورواية عن أحمد , وروي أيضا عن القاسم , وقيل : إن عصبة أمه تصير عصبة له , وهو قول علي وابن عمر وهو المشهور عن أحمد , وبه قالت الهادوية . وقيل : ترثه أمه وأخته منها بالفرض والرد , وهو قول أبي عبيد ومحمد بن الحسن ورواية عن أحمد قال : فإن لم يرثه ذو فرض بحال فعصبته عصبة أمه . واستدل بحديث ابن عمر المذكور على مشروعية اللعان لنفي الولد , وعن أحمد ينتفي الولد بمجرد اللعان وإن لم يتعرض الرجل لذكره في اللعان . قال الحافظ : وفيه نظر لأنه لو استلحقه لحقه , وإنما يؤثر اللعان دفع حد القذف عنه وثبوت زنى المرأة وقال الشافعي : إن نفي الولد في الملاعنة انتفى وإن لم يتعرض له , فله أن يعيد اللعان لانتفائه ولا إعادة على المرأة , وإن أمكنه الرفع إلى الحاكم فأخر بغير عذر حتى ولدت لم يكن له أن ينفيه . كما في الشفعة , واستدل به أيضا على أنه لا يشترط في نفي الولد التصريح بأنها ولدته من زنى ولا بأنه استبرأها بحيضة . وعن المالكية يشترط ذلك . قوله : ( أرأيت لو وجد أحدنا ) أي أخبرني عن حكم من وقع له ذلك . قوله : ( على فاحشة ) اختلف العلماء فيمن وجد مع امرأته رجلا وتحقق وجود الفاحشة منهما فقتله هل يقتل به أم لا ؟ فمنع الجمهور الإقدام وقالوا : يقتص منه إلا أن يأتي ببينة الزنى أو يعترف المقتول بذلك بشرط أن يكون محصنا . وقيل : بل يقتل به لأنه ليس له أن يقيم الحد بغير إذن الإمام . وقال بعض السلف : لا يقتل أصلا ويعذر فيما فعله إذا ظهرت أمارات صدقه , وشرط أحمد وإسحاق ومن تبعهما أن يأتي بشاهدين أنه قتله بسبب ذلك . ووافقهم ابن القاسم وابن حبيب من المالكية لكن زاد أن يكون المقتول قد أحصن وعند الهادوية أنه يجوز للرجل أن يقتل من وجده مع زوجته وأمته وولده حال الفعل , وأما بعده فيقاد به إن كان بكرا . قوله : ( ووعظه وذكره ) فيه دليل على أنه يشرع للإمام موعظة المتلاعنين قبل اللعان تحذيرا لهما منه وتخويفا لهما من الوقوع في المعصية . قوله : ( فبدأ بالرجل ) فيه دليل على أنه يبدأ الإمام في اللعان بالرجل . وقد حكى الإمام المهدي في البحر الإجماع . أن السنة تقديم الزوج . واختلف في الوجوب ; فذهب الشافعي ومن تبعه وأشهب من المالكية ورجحه ابن العربي إلى أنه واجب وهو قول المؤيد بالله وأبي طالب وأبي العباس والإمام يحيى . وذهب الحنفية ومالك وابن القاسم إلى أنه لو وقع الابتداء بالمرأة صح واعتد به ; واحتجوا بأن الله تعالى عطف في القرآن بالواو وهو لا يقتضي الترتيب ; واحتج الأولون أيضا بأن اللعان يشرع لدفع الحد عن الرجل , ويؤيده قوله صلى الله عليه وسلم لهلال : \" البينة وإلا حد في ظهرك \" وسيأتي , فلو بدأ بالمرأة لكان دفعا لأمر لم يثبت . قوله : ( بين أخوي بني عجلان ) بفتح العين المهملة وسكون الجيم وهو ابن حارثة بن ضبيعة من بني بكر بن عمرو , والمراد بقوله \" أخوي \" الرجل وامرأته , واسم الرجل عويمر كما في الرواية المذكورة , واسم المرأة خولة بنت عاصم بن عدي العجلاني قاله ابن منده في كتاب الصحابة وأبو نعيم وحكى القرطبي عن مقاتل بن سليمان أنها خولة بنت قيس , وذكر ابن مردويه أنها بنت أخي عاصم المذكور , والرجل الذي رمى عويمر امرأته به هو شريك بن سحماء ابن عم عويمر , وفي صحيح مسلم من حديث أنس : { أن هلال بن أمية قذف امرأته بشريك بن سحماء وكان أخا البراء بن مالك لأمه } وسيأتي , وكان أول رجل لاعن في الإسلام . قال النووي في شرح مسلم : السبب في نزول آية اللعان قصة عويمر العجلاني واستدل على ذلك بقوله صلى الله عليه وسلم له : { قد أنزل الله فيك وفي صاحبتك قرآنا } وقال الجمهور . : السبب قصة هلال بن أمية لما تقدم من أنه كان أول رجل لاعن في الإسلام . وقد حكى أيضا الماوردي عن الأكثر أن قصة هلال أسبق من قصة عويمر . وقال الخطيب والنووي وتبعهما الحافظ : يحتمل أن يكون هلال سأله أولا ثم سأل عويمرا فنزلت في شأنهما معا وقال ابن الصباغ في الشامل : قصة هلال بن أمية نزلت فيها الآية . وأما قوله صلى الله عليه وسلم لعويمر : \" إن الله قد أنزل فيك وفي صاحبتك \" فمعناه ما نزل في قصة هلال لأن ذلك حكم عام لجميع الناس . واختلف في الوقت الذي وقع فيه اللعان ; فجزم الطبري وأبو حاتم وابن حبان أنه كان في شهر شعبان سنة تسع , وقيل : كان في السنة التي توفي فيها رسول الله صلى الله عليه وسلم , لما وقع في البخاري عن سهل بن سعد أنه شهد قصة المتلاعنين وهو ابن خمس عشرة سنة , وقد ثبت عنه أنه قال توفي رسول الله صلى الله عليه وسلم وأنا ابن خمس عشرة سنة . وقيل : كانت القصة في سنة عشر , ووفاته صلى الله عليه وسلم في سنة إحدى عشرة . قوله : ( فطلقها ثلاثا ) وفي رواية أنه قال : فهي الطلاق فهي الطلاق فهي الطلاق وقد استدل بذلك من قال : إن الفرقة بين المتلاعنين تتوقف على تطليق الرجل كما تقدم نقله عن عثمان البتي . وأجيب بما في حديث سهل نفسه من تفريقه صلى الله عليه وسلم بينهما وبما في حديث ابن عمر كما ذكر ذلك المصنف فإن ظاهرهما أن الفرقة وقعت بتفريق النبي صلى الله عليه وسلم وإنما طلقها عويمر لظنه أن اللعان لا يحرمها عليه فأراد تحريمها بالطلاق فقال : طالق ثلاثا , فقال له النبي صلى الله عليه وسلم لا سبيل لك عليها أي لا ملك لك عليها فلا يقع طلاق . قال الحافظ : وقد توهم أن قوله : \" لا سبيل لك عليها \" وقع منه صلى الله عليه وسلم عقب قول الملاعن هي طالق , وأنه موجود كذلك في حديث سهل , وإنما وقع في حديث ابن عمر عقب قوله : { الله يعلم أن أحدكما كاذب , لا سبيل لك عليها } انتهى . وقد قدمنا ما جاء في طلاق البتة الجواب عن الاستدلال بهذا الحديث على أن الطلاق المتتابع يقع : قوله : ( فكانت سنة المتلاعنين ) زاد أبو داود عن القعنبي عن مالك \" فكانت تلك \" وهي إشارة إلى الفرقة . وفي الرواية الأخرى المذكورة ذاكم التفريق بين كل متلاعنين وقال مسلم : إن قوله : وكان فراقه إياها سنة بين المتلاعنين مدرج . وكذا ذكر الدارقطني في غريب مالك اختلاف الرواة على ابن شهاب ثم على مالك في تعيين من قال : \" فكان فراقهما سنة \" هل هو من قول سهل , أو من قول ابن شهاب ؟ وذكر ذلك الشافعي وأشار إلى أن نسبته إلى ابن شهاب لا تمنع نسبته إلى سهل ويؤيد ذلك ما وقع في رواية لأبي داود عن سهل قال : { فطلقها ثلاث تطليقات عند رسول الله صلى الله عليه وسلم , فأنفذه رسول الله صلى الله عليه وسلم , وكان ما صنع عند رسول الله صلى الله عليه وسلم سنة } وسيأتي قريبا . وفي نسخة الصاغاني قال أبو عبد الله : قوله : \" ذلك تفريق بين المتلاعنين \" من قول الزهري وليس من الحديث\n",
      " with length = 7543\n",
      "shortest sentence is ذلك\n",
      " with length = 4\n"
     ]
    }
   ],
   "source": [
    "longest_sentence = \"\"\n",
    "shortest_sentence = \"\"\n",
    "max_len = 0\n",
    "min_len = 1000000000\n",
    "for t in train_dataset:\n",
    "    t,_ = remove_diacritics_and_save(t)\n",
    "    if (len(t) > max_len):\n",
    "        max_len = len(t)\n",
    "        longest_sentence= t\n",
    "        \n",
    "    if (len(t) < min_len):\n",
    "        min_len = len(t)\n",
    "        shortest_sentence = t\n",
    "        \n",
    "\n",
    "print(f\"longest sentence is {longest_sentence} with length = {max_len}\")\n",
    "print(f\"shortest sentence is {shortest_sentence} with length = {min_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1885.75\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qalsadi in c:\\users\\mai\\anaconda3\\lib\\site-packages (0.5)\n",
      "Requirement already satisfied: pyarabic>=0.6.7 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.6.15)\n",
      "Requirement already satisfied: tashaphyne>=0.3.4.1 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.3.6)\n",
      "Requirement already satisfied: Arabic-Stopwords>=0.4.2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.4.3)\n",
      "Requirement already satisfied: naftawayh>=0.3 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.4)\n",
      "Requirement already satisfied: mysam-tagmanager>=0.3.3 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.4)\n",
      "Requirement already satisfied: arramooz-pysqlite>=0.4.2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.4.2)\n",
      "Requirement already satisfied: libqutrub>=1.2.3 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (1.2.4.1)\n",
      "Requirement already satisfied: alyahmor>=0.2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.2)\n",
      "Requirement already satisfied: pickledb>=0.9.2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.9.2)\n",
      "Requirement already satisfied: codernitydb3 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from qalsadi) (0.6.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from pyarabic>=0.6.7->qalsadi) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install qalsadi\n",
    "import qalsadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qalsadi.lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['عل']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "lemmas = lemmer.lemmatize_text('فعل')\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Requirement already satisfied: FarasaPy3 in c:\\users\\mai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --index-url https://test.pypi.org/simple/ --no-deps FarasaPy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement FarasaPy3 (from versions: none)\n",
      "ERROR: No matching distribution found for FarasaPy3\n"
     ]
    }
   ],
   "source": [
    "%pip install FarasaPy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'FarasaPy3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mFarasaPy3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFarasaPy3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FarasaPy3\n\u001b[0;32m      3\u001b[0m farasaApi \u001b[38;5;241m=\u001b[39m FarasaPy3()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'FarasaPy3'"
     ]
    }
   ],
   "source": [
    "import FarasaPy3\n",
    "from FarasaPy3.api import FarasaPy3\n",
    "farasaApi = FarasaPy3()\n",
    "result = farasaApi.Segmentation(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Features:\n",
    "1) last char identity\n",
    "2) raw word\n",
    "3) context\n",
    "4) context class\n",
    "5) POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: farasa in c:\\users\\mai\\anaconda3\\lib\\site-packages (0.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install farasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'farasa' has no attribute 'farasa_pos_tagger'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfarasa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# import FarasaPOSTagger\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m farasa_pos_tagger \u001b[38;5;241m=\u001b[39m \u001b[43mfarasa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfarasa_pos_tagger\u001b[49m(interactive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mهذا مثال على استخدام تسميات أجزاء الكلام في اللغة العربية.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m pos_tags \u001b[38;5;241m=\u001b[39m farasa_pos_tagger\u001b[38;5;241m.\u001b[39mtag(text)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'farasa' has no attribute 'farasa_pos_tagger'"
     ]
    }
   ],
   "source": [
    "import farasa\n",
    "# import FarasaPOSTagger\n",
    "farasa_pos_tagger = farasa.farasa_pos_tagger(interactive=True)\n",
    "\n",
    "text = \"هذا مثال على استخدام تسميات أجزاء الكلام في اللغة العربية.\"\n",
    "pos_tags = farasa_pos_tagger.tag(text)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install arabicnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('يذهب', 'NN'), ('علي', 'NN')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arabicnlp\n",
      "  Using cached arabicnlp-0.1.7-py3-none-any.whl (14.4 MB)\n",
      "Collecting keras\n",
      "  Using cached keras-3.0.1-py3-none-any.whl (999 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\mai\\anaconda3\\lib\\site-packages (from keras->arabicnlp) (3.6.0)\n",
      "Collecting dm-tree\n",
      "  Using cached dm_tree-0.1.8-cp39-cp39-win_amd64.whl (101 kB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from keras->arabicnlp) (1.26.2)\n",
      "Collecting rich\n",
      "  Using cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras->arabicnlp) (2.13.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\http\\client.py\", line 463, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\http\\client.py\", line 507, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 173, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 203, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 315, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 472, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 366, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 212, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 203, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 140, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 128, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 32, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 204, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 295, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 305, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\Mai\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)\", ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "sentence = \"يذهب علي\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arabicnlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01marabicnlp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arabicnlp'"
     ]
    }
   ],
   "source": [
    "import arabicnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import requests\n",
    "# url = 'https://farasa.qcri.org/webapi/pos/'\n",
    "# text = 'يُشار إلى أن اللغة العربية' \n",
    "# api_key = \"#####################\"\n",
    "# payload = {'text': text, 'api_key': api_key}\n",
    "# data = requests.post(url, data=payload)\n",
    "# result = json.loads(data.text)\n",
    "# print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stanfordnlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstanfordnlp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set the path to the Arabic POS Tagger JAR file and models\u001b[39;00m\n\u001b[0;32m      4\u001b[0m arabic_pos_tagger_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/stanford-postagger-3.9.2.jar\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stanfordnlp'"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "\n",
    "# Set the path to the Arabic POS Tagger JAR file and models\n",
    "arabic_pos_tagger_path = '/path/to/stanford-postagger-3.9.2.jar'\n",
    "arabic_pos_model_path = '/path/to/arabic-ud.tagger'\n",
    "\n",
    "# Initialize the Arabic POS Tagger\n",
    "arabic_pos_tagger = stanfordnlp.Pipeline(processors='tokenize,pos', pos_model_path=arabic_pos_model_path, pos_jar_path=arabic_pos_tagger_path, lang='ar')\n",
    "\n",
    "# Example text\n",
    "text = \"هذا مثال على استخدام تسميات أجزاء الكلام في اللغة العربية.\"\n",
    "\n",
    "# Process the text and obtain POS tags\n",
    "doc = arabic_pos_tagger(text)\n",
    "\n",
    "# Access POS tags for each word in the text\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(f'{word.text}: {word.pos}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
